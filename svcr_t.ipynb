{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SequentialSampler, RandomSampler, BatchSampler\n",
    "from torchvision import models, transforms\n",
    "from torch import nn, optim\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.clean_labels import clean_labels\n",
    "from utils.prepare_images import prepare_images\n",
    "from utils.build_dataset import SVRCDataset\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import random\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put videos here!\n",
    "video_base = 'data/videos'\n",
    "#video_base = 'D:/e6691/6691_assignment2/videos'\n",
    "videos = os.listdir(video_base)\n",
    "# images will be output to here\n",
    "image_base = 'data/images'\n",
    "#image_base = 'D:/e6691/6691_assignment2/images'\n",
    "if not os.path.exists(image_base):\n",
    "    os.mkdir(image_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = sorted(videos)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command line: \n",
    "# ffmpeg -i {input_video} -r {frame_rate} [-f {force_format} (not needed)] {output_images}\n",
    "# doc: https://ffmpeg.org/ffmpeg.html\n",
    "for video in videos:\n",
    "    input_path = os.path.join(video_base, video)\n",
    "    # make dirs\n",
    "    output_base = image_base + '/{}'.format(video.split('.')[0])\n",
    "    if not os.path.exists(output_base):\n",
    "        os.mkdir(output_base)\n",
    "    output_path = os.path.join(output_base, '%d.png')\n",
    "    # # command\n",
    "    # print('Frames extracted from {} to {}'.format(input_path, output_path))\n",
    "    # !ffmpeg -i {input_path} -r 1 {output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = 'data/labels/video.phase.trainingData.clean.StudentVersion.csv'\n",
    "#labels_path = 'D:/e6691/6691_assignment2/labels/video.phase.trainingData.clean.StudentVersion.csv'\n",
    "names_path = 'data/labels/all_labels_hernia.csv'\n",
    "#names_path = 'D:/e6691/6691_assignment2/labels/names.csv'\n",
    "labels_df = pd.read_csv(labels_path)\n",
    "names_df = pd.DataFrame({'Name': list(set(labels_df['PhaseName'].to_list()))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoName</th>\n",
       "      <th>PhaseName</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RALIHR_surgeon01_fps01_0001</td>\n",
       "      <td>stationary idle</td>\n",
       "      <td>00:00</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RALIHR_surgeon01_fps01_0001</td>\n",
       "      <td>transitionary idle</td>\n",
       "      <td>00:16</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RALIHR_surgeon01_fps01_0001</td>\n",
       "      <td>out of body</td>\n",
       "      <td>00:35</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RALIHR_surgeon01_fps01_0001</td>\n",
       "      <td>transitionary idle</td>\n",
       "      <td>01:05</td>\n",
       "      <td>01:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RALIHR_surgeon01_fps01_0001</td>\n",
       "      <td>peritoneal scoring</td>\n",
       "      <td>01:59</td>\n",
       "      <td>02:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>RALIHR_surgeon01_fps01_0070</td>\n",
       "      <td>peritoneal closure</td>\n",
       "      <td>51:24</td>\n",
       "      <td>52:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>RALIHR_surgeon01_fps01_0070</td>\n",
       "      <td>positioning suture</td>\n",
       "      <td>52:23</td>\n",
       "      <td>54:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>RALIHR_surgeon01_fps01_0070</td>\n",
       "      <td>peritoneal closure</td>\n",
       "      <td>54:08</td>\n",
       "      <td>57:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>RALIHR_surgeon01_fps01_0070</td>\n",
       "      <td>positioning suture</td>\n",
       "      <td>57:27</td>\n",
       "      <td>57:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>RALIHR_surgeon01_fps01_0070</td>\n",
       "      <td>transitionary idle</td>\n",
       "      <td>57:55</td>\n",
       "      <td>58:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2022 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        videoName           PhaseName  Start    End\n",
       "0     RALIHR_surgeon01_fps01_0001     stationary idle  00:00  00:16\n",
       "1     RALIHR_surgeon01_fps01_0001  transitionary idle  00:16  00:35\n",
       "2     RALIHR_surgeon01_fps01_0001         out of body  00:35  01:05\n",
       "3     RALIHR_surgeon01_fps01_0001  transitionary idle  01:05  01:59\n",
       "4     RALIHR_surgeon01_fps01_0001  peritoneal scoring  01:59  02:55\n",
       "...                           ...                 ...    ...    ...\n",
       "2017  RALIHR_surgeon01_fps01_0070  peritoneal closure  51:24  52:23\n",
       "2018  RALIHR_surgeon01_fps01_0070  positioning suture  52:23  54:08\n",
       "2019  RALIHR_surgeon01_fps01_0070  peritoneal closure  54:08  57:27\n",
       "2020  RALIHR_surgeon01_fps01_0070  positioning suture  57:27  57:55\n",
       "2021  RALIHR_surgeon01_fps01_0070  transitionary idle  57:55  58:18\n",
       "\n",
       "[2022 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/images/R'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6334/2724024585.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprepare_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/e6691-2022spring-assign2-vcsz/utils/prepare_images.py\u001b[0m in \u001b[0;36mprepare_images\u001b[0;34m(video_base, image_base, labels_df, names_df, image_ext)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m92\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         images = [\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mdir\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_ext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         ]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/images/R'"
     ]
    }
   ],
   "source": [
    "prepare_images(video_base, image_base, labels_df, names_df, 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RALIHR_surgeon01_fps01_0093.mp4\n"
     ]
    }
   ],
   "source": [
    "# get all images and labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for video in sorted(videos):\n",
    "    base = os.path.join(image_base, video.split('.')[0])\n",
    "    image_paths += list(map(\n",
    "        lambda img: os.path.join(base, img), \n",
    "        os.listdir(base)\n",
    "    ))\n",
    "#     image_paths += list(map(\n",
    "#         lambda img: base + '/' + img,\n",
    "#         os.listdir(base)\n",
    "#     ))\n",
    "    labels += list(map(\n",
    "        lambda img: int(img.split('.')[0].split('-')[1]), \n",
    "        os.listdir(base)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_images(x):\n",
    "    vid = int(x[0].split('_')[-1].split('/')[0])\n",
    "    frame = int(x[0].split('/')[-1].split('-')[0])\n",
    "    return vid*7200 + frame\n",
    "\n",
    "image_paths_lstm = []\n",
    "labels_lstm = []\n",
    "for path,label in sorted(zip(image_paths, labels), key=sort_images):\n",
    "    image_paths_lstm.append(path)\n",
    "    labels_lstm.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters LSTM\n",
    "\n",
    "TRAIN_SIZE = int(0.7 * len(image_paths))\n",
    "TEST_SIZE = len(image_paths) - TRAIN_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of labels\n",
    "num_labels = 14\n",
    "\n",
    "# define transforms\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "    ])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVRC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVRC,self).__init__()\n",
    "        # ResNet-18\n",
    "        self.resnet18 = nn.Sequential(*(\n",
    "            list(\n",
    "                models.resnet18(pretrained=True).children()\n",
    "            )[:-1]\n",
    "        ))\n",
    "        #self.resnet18.eval()\n",
    "        self.pretrain = True\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(512,512)\n",
    "        self.lstm_states = None\n",
    "        # FC\n",
    "        self.full = nn.Linear(512,num_labels)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.resnet18(x)\n",
    "        # Reshape\n",
    "        #print(x.shape)\n",
    "        if not self.pretrain:\n",
    "            x = x.view(3,1,-1) # time step, batch size\n",
    "            x,s = self.lstm(x, self.lstm_states)\n",
    "            # save lstm states\n",
    "            self.lstm_states = (s[0].detach(), s[1].detach())\n",
    "            \n",
    "        x = self.full(x.view(-1,512))\n",
    "        return x #if self.pretrain else nn.Softmax(1)(x).view(30,-1)\n",
    "    def predict(self, features, labels, BATCH_SIZE, transform):\n",
    "        self.eval()\n",
    "        dataset = SVRCDataset(features, labels, transform)\n",
    "        loader = DataLoader(\n",
    "            dataset, batch_sampler=BatchSampler(\n",
    "                SequentialSampler(dataset), \n",
    "                BATCH_SIZE, \n",
    "                drop_last=True\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        test_acc = 0.0\n",
    "        predicts = []\n",
    "        for i, data in enumerate(loader):\n",
    "            features = data['feature'].float()\n",
    "            labels = data['label']\n",
    "            predictions = self.forward(features)\n",
    "            preds = torch.max(predictions.data, 1)[1]\n",
    "            predicts.append(preds)\n",
    "            test_acc += (preds == labels).sum().item()\n",
    "        test_acc /= len(dataset)\n",
    "        print(f'test_acc:{test_acc}')\n",
    "        return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVRCDataset(Dataset):\n",
    "    def __init__(self, image_path: list, image_class: list=None, transform=None):\n",
    "        self.image_path = image_path\n",
    "        self.image_class = image_class\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "\n",
    "    def __getitem__(self, item): #can add more rules to pick data\n",
    "        img = Image.open(self.image_path[item])\n",
    "        if self.image_class is not None:\n",
    "            label = self.image_class[item]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return {'feature': img, 'label': label} if self.image_class is not None else {'feature': img}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetTrainVal(object):\n",
    "    def __init__(self, model, device, EPOCH, BATCH_SIZE, LR) -> None:\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.EPOCH = EPOCH\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.LR = LR\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.LR)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self, labels, features, transform):\n",
    "        print('Training ResNet: ')\n",
    "\n",
    "        dataset = SVRCDataset(features, labels, transform)\n",
    "        train, test = random_split(dataset, [TRAIN_SIZE, TEST_SIZE])\n",
    "        print(len(train))\n",
    "        train_loader = DataLoader(train, self.BATCH_SIZE, shuffle=True)\n",
    "        test_loader = DataLoader(test, self.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "        self.model.pretrain = True\n",
    "\n",
    "        for epoch in range(self.EPOCH):\n",
    "            self.model.train()\n",
    "\n",
    "            train_loss = 0.0\n",
    "            train_acc = 0.0\n",
    "\n",
    "            for i, data in enumerate(train_loader):\n",
    "            \n",
    "                features = data['feature'].float()\n",
    "                labels = data['label']\n",
    "            \n",
    "                # features  = data['feature'].float()\n",
    "                # labels = data['label']\n",
    "                features, labels = features.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                predictions = self.model(features)\n",
    "                loss = self.criterion(predictions, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                preds = torch.max(predictions.data, 1)[1]\n",
    "                train_acc += (preds==labels).sum().item()\n",
    "            \n",
    "            train_loss /= len(train)\n",
    "            train_acc /= len(train)\n",
    "\n",
    "            valid_loss = 0.0\n",
    "            valid_acc = 0.0\n",
    "            total = 0\n",
    "            self.model.eval()\n",
    "            for i, data in enumerate(test_loader):\n",
    "                features = data['feature']\n",
    "                labels = data['label']\n",
    "\n",
    "                features, labels = features.to(self.device), labels.to(self.device)\n",
    "                predictions = self.model(features)\n",
    "                loss = self.criterion(predictions,labels)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "                preds = torch.max(predictions.data, 1)[1]\n",
    "                valid_acc += (preds==labels).sum().item()\n",
    "                total += features.size(0)\n",
    "\n",
    "            valid_loss /= len(test)\n",
    "            valid_acc /= len(test)\n",
    "\n",
    "            print(\n",
    "                f'Epoch {epoch+1} Training Loss: {train_loss} Train_acc: {train_acc}'\n",
    "                f'|| Validation Loss: {valid_loss} Valid_acc: {valid_acc}'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmTrainVal(object):\n",
    "    def __init__(self, model,device, EPOCH, BATCH_SIZE, LR) -> None:\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.EPOCH = EPOCH\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.LR = LR\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.LR)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self, labels, features, transform, eval_intval=3):\n",
    "        dataset = SVRCDataset(features, labels, transform)\n",
    "        data_loader = DataLoader(\n",
    "            dataset, batch_sampler=BatchSampler(\n",
    "                SequentialSampler(dataset), \n",
    "                self.BATCH_SIZE, \n",
    "                drop_last=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.model.pretrain = False\n",
    "\n",
    "        for epoch in range(self.EPOCH):\n",
    "            if (epoch + 1) % eval_intval == 0:\n",
    "                self.model.eval()\n",
    "            else:\n",
    "                self.model.lstm.train()\n",
    "                self.model.full.train()\n",
    "\n",
    "            train_loss = 0.0\n",
    "            train_acc = 0.0\n",
    "\n",
    "            for i, data in enumerate(data_loader):\n",
    "                features  = data['feature'].float()\n",
    "                \n",
    "                labels = data['label']\n",
    "                features, labels = features.to(self.device), labels.to(self.device)\n",
    "                predictions = self.model(features)\n",
    "                loss = self.criterion(predictions, labels)\n",
    "\n",
    "                if not (epoch + 1) % eval_intval == 0:\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                preds = torch.max(predictions.data, 1)[1]\n",
    "                train_acc += (preds==labels).sum().item()\n",
    "\n",
    "            train_loss /= len(dataset)\n",
    "            train_acc /= len(dataset)\n",
    "\n",
    "            print('Epoch {} - {} Loss: {} Acc: {} LSTM'.format(\n",
    "                epoch+1, 'Train' if not (epoch + 1) % eval_intval == 0 else 'Valid', \n",
    "                train_loss, train_acc\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "WeightsPath = './models/weights_resnet18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet: \n",
      "150539\n",
      "Epoch 1 Training Loss: 0.024475088597899253 Train_acc: 0.7605404579544172|| Validation Loss: 0.01592618384509064 Valid_acc: 0.8422455748783285\n",
      "Epoch 2 Training Loss: 0.013247700232216423 Train_acc: 0.8697613243079866|| Validation Loss: 0.010955648369718301 Valid_acc: 0.8920766297777365\n",
      "Epoch 3 Training Loss: 0.009097111920864289 Train_acc: 0.9110928065152551|| Validation Loss: 0.010903670767681848 Valid_acc: 0.9068167023156328\n",
      "Epoch 4 Training Loss: 0.00716468797997593 Train_acc: 0.9294601398973024|| Validation Loss: 0.007357738582379434 Valid_acc: 0.9282215815741344\n",
      "Epoch 5 Training Loss: 0.005694102683291168 Train_acc: 0.9441473638060569|| Validation Loss: 0.007043369710279112 Valid_acc: 0.9330574413342013\n",
      "Time:2.2e+02min\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "X = image_paths\n",
    "y = labels\n",
    "\n",
    "# resnet18 Model\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "model = SVRC()\n",
    "if torch.cuda.is_available:\n",
    "    model.to(device)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.pretrain = True\n",
    "trainer = ResnetTrainVal(model, device, 5, 30, 1e-3)\n",
    "trainer.train(y, X, data_transform['train'])\n",
    "\n",
    "torch.save(model.state_dict(),WeightsPath+'_70')\n",
    "\n",
    "end_time = time.time()\n",
    "print('Time:{:.2}min'.format((end_time-start_time)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset for test\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for video in sorted(videos)[92:93]:\n",
    "    base = os.path.join(image_base, video.split('.')[0])\n",
    "    # image_paths += list(map(\n",
    "    #     lambda img: os.path.join(base, img), \n",
    "    #     os.listdir(base)\n",
    "    # ))\n",
    "    image_paths += list(map(\n",
    "        lambda img: base + '/' + img,\n",
    "        os.listdir(base)\n",
    "    ))\n",
    "    labels += list(map(\n",
    "        lambda img: int(img.split('.')[0].split('-')[1]), \n",
    "        os.listdir(base)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for test of ResNet\n",
    "def sort_images(x):\n",
    "    vid = int(x[0].split('_')[-1].split('/')[0])\n",
    "    frame = int(x[0].split('/')[-1].split('-')[0])\n",
    "    return vid*7200 + frame\n",
    "\n",
    "image_paths_test = []\n",
    "labels_test = []\n",
    "for path,label in sorted(zip(image_paths, labels), key=sort_images):\n",
    "    image_paths_test.append(path)\n",
    "    labels_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc:0.9575570223076281\n"
     ]
    }
   ],
   "source": [
    "WeightsPath = './models/weights_resnet18_70'\n",
    "X = image_paths_test\n",
    "y = labels_test\n",
    "model = SVRC()\n",
    "model.pretrain = True\n",
    "model.load_state_dict(torch.load(WeightsPath))\n",
    "a = model.predict(X, y, 30, transform = data_transform['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.3513061202120706 Acc: 0.6672370580822758 LSTM\n",
      "Epoch 2 - Train Loss: 0.22994594864438234 Acc: 0.7781425389547887 LSTM\n",
      "Epoch 3 - Train Loss: 0.17711631583863016 Acc: 0.8305472502638835 LSTM\n",
      "Epoch 4 - Train Loss: 0.14286621200371366 Acc: 0.8634966543753516 LSTM\n",
      "Epoch 5 - Valid Loss: 1.6568060865719982 Acc: 0.06767043156000502 LSTM\n",
      "Epoch 6 - Train Loss: 0.13071372540655407 Acc: 0.8784601291750559 LSTM\n",
      "Epoch 7 - Train Loss: 0.02568127496087503 Acc: 0.9765132034762877 LSTM\n",
      "Epoch 8 - Train Loss: 0.01870487627525775 Acc: 0.9830696048024478 LSTM\n",
      "Epoch 9 - Train Loss: 0.014655133675175227 Acc: 0.9870452949683107 LSTM\n",
      "Epoch 10 - Valid Loss: 0.013645206177535833 Acc: 0.9879659811119843 LSTM\n",
      "Epoch 11 - Train Loss: 0.011677250751410293 Acc: 0.9900026504601106 LSTM\n",
      "Epoch 12 - Train Loss: 0.009359580709360157 Acc: 0.9922857660992203 LSTM\n",
      "Epoch 13 - Train Loss: 0.007874114600798314 Acc: 0.9938062932152871 LSTM\n",
      "Epoch 14 - Train Loss: 0.006684266908701929 Acc: 0.9946665302687194 LSTM\n",
      "Epoch 15 - Valid Loss: 0.00744534657739287 Acc: 0.9938527925154726 LSTM\n",
      "Epoch 16 - Train Loss: 0.006054125570975509 Acc: 0.9954477185118364 LSTM\n",
      "Epoch 17 - Train Loss: 0.005385688038841429 Acc: 0.996024309834137 LSTM\n",
      "Epoch 18 - Train Loss: 0.005054180858167087 Acc: 0.9962196068949162 LSTM\n",
      "Epoch 19 - Train Loss: 0.004537548167951986 Acc: 0.9967589987770684 LSTM\n",
      "Epoch 20 - Valid Loss: 0.005805930077007439 Acc: 0.995494217812022 LSTM\n",
      "Time:1.3e+03min\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "WeightsPath = './models/weights_resnet18_70'\n",
    "X = image_paths_lstm\n",
    "y = labels_lstm\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "# SVRC Model\n",
    "model = SVRC()\n",
    "if torch.cuda.is_available():\n",
    "    model.to(device)\n",
    "\n",
    "model.pretrain = False\n",
    "model.load_state_dict(torch.load(WeightsPath))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "trainer = LstmTrainVal(model, device, 20, 3, 1e-5)\n",
    "trainer.train(y, X, data_transform['train'])\n",
    "torch.save(model.state_dict(),WeightsPath+'_LSTM')\n",
    "end_time = time.time()\n",
    "print('Time:{:.2}min'.format((end_time-start_time)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc:0.0\n"
     ]
    }
   ],
   "source": [
    "WeightsPath = './models/weights_resnet18_70_LSTM'\n",
    "X = image_paths_test\n",
    "y = labels_test\n",
    "model = SVRC()\n",
    "model.pretrain = False\n",
    "model.load_state_dict(torch.load(WeightsPath, map_location=device))\n",
    "a = model.predict(X, y, 3, transform = data_transform['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetEvaluator:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def predict(self, images, transform):\n",
    "        dataset = SVRCDataset(images, None, transform)\n",
    "        loader = DataLoader(dataset, batch_size=3, drop_last=True)\n",
    "        preds = []\n",
    "        self.model.eval()\n",
    "        for i,data in enumerate(loader):\n",
    "            feature = data['feature'].float().to(self.device)\n",
    "            pred = torch.max(self.model(feature).data, 1)[1]\n",
    "            preds.append(pred)\n",
    "        return preds\n",
    "\n",
    "    def eval(self, preds, labels):\n",
    "        acc = sum([p.item() == l for p,l in zip(preds, labels)]) / len(labels)\n",
    "        print('Accuracy: {}'.format(acc))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:0.84min\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "WeightsPath = './models/weights_resnet18_70'\n",
    "X = image_paths_test\n",
    "y = labels_test\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# SVRC Model\n",
    "model = SVRC()\n",
    "if torch.cuda.is_available():\n",
    "    model.to(device)\n",
    "#print(model)\n",
    "\n",
    "model.pretrain = False\n",
    "model.load_state_dict(torch.load(WeightsPath, map_location=device), strict=False)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "evaluator = ResnetEvaluator(model, device)\n",
    "preds = evaluator.predict(X, data_transform['train'])\n",
    "#acc = evaluator.eval(preds, y)\n",
    "\n",
    "end_time = time.time()\n",
    "print('Time:{:.2}min'.format((end_time-start_time)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([8, 5, 3]),\n",
       " tensor([ 5,  5, 11]),\n",
       " tensor([11, 11,  7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11,  7]),\n",
       " tensor([7, 5, 5]),\n",
       " tensor([ 5,  5, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11,  5,  5]),\n",
       " tensor([ 5,  5, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11,  5,  1]),\n",
       " tensor([ 5, 11,  5]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 5]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 5, 7]),\n",
       " tensor([5, 5, 7]),\n",
       " tensor([7, 7, 5]),\n",
       " tensor([7, 5, 5]),\n",
       " tensor([5, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 5, 5]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([5, 7, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 5]),\n",
       " tensor([7, 5, 5]),\n",
       " tensor([5, 7, 7]),\n",
       " tensor([7, 7, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([5, 5, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 7, 7]),\n",
       " tensor([7, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([7, 7, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([11,  5,  5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 3]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([7, 7, 3]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 7, 7]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 7]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([ 7, 11, 11]),\n",
       " tensor([11,  1,  1]),\n",
       " tensor([1, 1, 1]),\n",
       " tensor([ 1,  5, 11]),\n",
       " tensor([1, 1, 1]),\n",
       " tensor([1, 1, 1]),\n",
       " tensor([ 1,  1, 11]),\n",
       " tensor([1, 1, 1]),\n",
       " tensor([11,  1, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([ 7,  7, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11,  7]),\n",
       " tensor([7, 7, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 5, 5]),\n",
       " tensor([5, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 7, 7]),\n",
       " tensor([7, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 7]),\n",
       " tensor([7, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([7, 5, 5]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 5]),\n",
       " tensor([11, 11,  5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 7]),\n",
       " tensor([5, 7, 7]),\n",
       " tensor([7, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 7, 7]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 7]),\n",
       " tensor([7, 5, 5]),\n",
       " tensor([7, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 7, 7]),\n",
       " tensor([7, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 7]),\n",
       " tensor([7, 7, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([ 5, 11, 11]),\n",
       " tensor([11,  1,  1]),\n",
       " tensor([1, 1, 1]),\n",
       " tensor([1, 1, 1]),\n",
       " tensor([ 7, 11, 11]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([11,  5,  5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([3, 5, 3]),\n",
       " tensor([3, 3, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([ 5, 11, 11]),\n",
       " tensor([11,  5,  5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([ 5, 12,  5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([ 5,  5, 12]),\n",
       " tensor([ 5,  5, 11]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([ 5, 12, 12]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([2, 6, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 6, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 1, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([ 5, 11, 11]),\n",
       " tensor([11,  5,  5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([ 5, 11, 11]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([ 5, 11, 11]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([ 5,  5, 11]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 7, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([11,  5, 11]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([11,  7,  5]),\n",
       " tensor([5, 5, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([11, 11,  5]),\n",
       " tensor([5, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 7, 7]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([ 5, 11, 11]),\n",
       " tensor([11,  7,  7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([ 7, 11,  5]),\n",
       " tensor([ 5, 11,  7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([ 7,  7, 11]),\n",
       " tensor([11, 11,  7]),\n",
       " tensor([11, 11,  5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([ 5, 11, 11]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([ 5, 11, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([ 5, 11, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11,  5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([ 5, 11, 11]),\n",
       " tensor([7, 7, 7]),\n",
       " tensor([ 7, 11, 11]),\n",
       " tensor([ 7, 11,  5]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11,  5]),\n",
       " tensor([ 5,  5, 11]),\n",
       " tensor([11,  5, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11,  5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([ 5, 11,  5]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11,  5, 11]),\n",
       " tensor([11, 11,  5]),\n",
       " tensor([ 5,  5, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11,  5]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([ 5, 11, 11]),\n",
       " tensor([11, 11, 11]),\n",
       " tensor([ 7,  7, 11]),\n",
       " tensor([11,  5,  5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([ 5, 11, 11]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([5, 5, 5]),\n",
       " tensor([ 5,  5, 11]),\n",
       " ...]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7bb744823c5315bc838d6f85bb474c2716845bb0b4d758ac389cca5a4bd648da"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
