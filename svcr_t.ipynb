{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "11.3\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SequentialSampler, RandomSampler, BatchSampler\n",
    "from torchvision import models, transforms\n",
    "from torch import nn, optim\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.clean_labels import clean_labels\n",
    "from utils.prepare_images import prepare_images\n",
    "from utils.build_dataset import SVRCDataset\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import random\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put videos here!\n",
    "# video_base = 'data/videos'\n",
    "video_base = 'D:/e6691/6691_assignment2/videos'\n",
    "videos = os.listdir(video_base)\n",
    "# images will be output to here\n",
    "# image_base = 'data/images'\n",
    "image_base = 'D:/e6691/6691_assignment2/images'\n",
    "if not os.path.exists(image_base):\n",
    "    os.mkdir(image_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command line: \n",
    "# ffmpeg -i {input_video} -r {frame_rate} [-f {force_format} (not needed)] {output_images}\n",
    "# doc: https://ffmpeg.org/ffmpeg.html\n",
    "for video in videos:\n",
    "    input_path = os.path.join(video_base, video)\n",
    "    # make dirs\n",
    "    output_base = image_base + '/{}'.format(video.split('.')[0])\n",
    "    if not os.path.exists(output_base):\n",
    "        os.mkdir(output_base)\n",
    "    output_path = os.path.join(output_base, '%d.png')\n",
    "    # # command\n",
    "    # print('Frames extracted from {} to {}'.format(input_path, output_path))\n",
    "    # !ffmpeg -i {input_path} -r 1 {output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_path = 'data/labels/video.phase.trainingData.clean.StudentVersion.csv'\n",
    "labels_path = 'D:/e6691/6691_assignment2/labels/video.phase.trainingData.clean.StudentVersion.csv'\n",
    "# names_path = 'data/labels/names.csv'\n",
    "names_path = 'D:/e6691/6691_assignment2/labels/names.csv'\n",
    "labels_df = pd.read_csv(labels_path)\n",
    "names_df = pd.DataFrame({'Name': list(set(labels_df['PhaseName'].to_list()))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\pandas\\core\\frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "prepare_images(video_base, image_base, labels_df, names_df, 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all images and labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for video in videos[:]:\n",
    "    base = os.path.join(image_base, video.split('.')[0])\n",
    "    # image_paths += list(map(\n",
    "    #     lambda img: os.path.join(base, img), \n",
    "    #     os.listdir(base)\n",
    "    # ))\n",
    "    image_paths += list(map(\n",
    "        lambda img: base + '/' + img,\n",
    "        os.listdir(base)\n",
    "    ))\n",
    "    labels += list(map(\n",
    "        lambda img: int(img.split('.')[0].split('-')[1]), \n",
    "        os.listdir(base)\n",
    "    ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 2 images and labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for video in videos[:2]:\n",
    "    base = os.path.join(image_base, video.split('.')[0])\n",
    "    # image_paths += list(map(\n",
    "    #     lambda img: os.path.join(base, img), \n",
    "    #     os.listdir(base)\n",
    "    # ))\n",
    "    image_paths += list(map(\n",
    "        lambda img: base + '/' + img,\n",
    "        os.listdir(base)\n",
    "    ))\n",
    "    labels += list(map(\n",
    "        lambda img: int(img.split('.')[0].split('-')[1]), \n",
    "        os.listdir(base)\n",
    "    ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_images(x):\n",
    "    vid = int(x[0].split('_')[-1].split('/')[0])\n",
    "    frame = int(x[0].split('/')[-1].split('-')[0])\n",
    "    return vid*7200 + frame\n",
    "\n",
    "image_paths_lstm = []\n",
    "labels_lstm = []\n",
    "for path,label in sorted(zip(image_paths, labels), key=sort_images):\n",
    "    image_paths_lstm.append(path)\n",
    "    \n",
    "    labels_lstm.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters LSTM\n",
    "\n",
    "TRAIN_SIZE = int(0.7 * len(image_paths))\n",
    "TEST_SIZE = len(image_paths) - TRAIN_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of labels\n",
    "num_labels = 14\n",
    "\n",
    "# define transforms\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "    ])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVRC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVRC,self).__init__()\n",
    "        # ResNet-18\n",
    "        self.resnet18 = nn.Sequential(*(\n",
    "            list(\n",
    "                models.resnet18(pretrained=True).children()\n",
    "            )[:-1]\n",
    "        ))\n",
    "        #self.resnet18.eval()\n",
    "        self.pretrain = True\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(512,512)\n",
    "        self.lstm_states = None\n",
    "        # FC\n",
    "        self.full = nn.Linear(512,num_labels)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.resnet18(x)\n",
    "        # Reshape\n",
    "        #print(x.shape)\n",
    "        if not self.pretrain:\n",
    "            x = x.view(3,1,-1) # time step, batch size\n",
    "            x,s = self.lstm(x, self.lstm_states)\n",
    "            # save lstm states\n",
    "            self.lstm_states = (s[0].detach(), s[1].detach())\n",
    "            \n",
    "        x = self.full(x.view(-1,512))\n",
    "        return x #if self.pretrain else nn.Softmax(1)(x).view(30,-1)\n",
    "    def predict(self, features, labels, BATCH_SIZE, transform):\n",
    "        self.eval()\n",
    "        dataset = SVRCDataset(features, labels, transform)\n",
    "        loader = DataLoader(\n",
    "            dataset, batch_sampler=BatchSampler(\n",
    "                SequentialSampler(dataset), \n",
    "                BATCH_SIZE, \n",
    "                drop_last=True\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        test_acc = 0.0\n",
    "        predicts = []\n",
    "        for i, data in enumerate(loader):\n",
    "            features = data['feature'].float()\n",
    "            labels = data['label']\n",
    "            predictions = self.forward(features)\n",
    "            preds = torch.max(predictions.data, 1)[1]\n",
    "            predicts.append(preds)\n",
    "            test_acc += (preds == labels).sum().item()\n",
    "        test_acc /= len(dataset)\n",
    "        print(f'test_acc:{test_acc}')\n",
    "        return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVRCDataset(Dataset):\n",
    "    def __init__(self, image_path: list, image_class: list=None, transform=None):\n",
    "        self.image_path = image_path\n",
    "        self.image_class = image_class\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "\n",
    "    def __getitem__(self, item): #can add more rules to pick data\n",
    "        img = Image.open(self.image_path[item])\n",
    "        if self.image_class is not None:\n",
    "            label = self.image_class[item]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return {'feature': img, 'label': label} if self.image_class is not None else {'feature': img}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetTrainVal(object):\n",
    "    def __init__(self, model, device, EPOCH, BATCH_SIZE, LR) -> None:\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.EPOCH = EPOCH\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.LR = LR\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.LR)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self, labels, features, transform):\n",
    "        print('Training ResNet: ')\n",
    "\n",
    "        dataset = SVRCDataset(features, labels, transform)\n",
    "        train, test = random_split(dataset, [TRAIN_SIZE, TEST_SIZE])\n",
    "        print(len(train))\n",
    "        train_loader = DataLoader(train, self.BATCH_SIZE, shuffle=True)\n",
    "        test_loader = DataLoader(test, self.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "        self.model.pretrain = True\n",
    "\n",
    "        for epoch in range(self.EPOCH):\n",
    "            self.model.train()\n",
    "\n",
    "            train_loss = 0.0\n",
    "            train_acc = 0.0\n",
    "\n",
    "            for i, data in enumerate(train_loader):\n",
    "            \n",
    "                features = data['feature'].float()\n",
    "                labels = data['label']\n",
    "            \n",
    "                # features  = data['feature'].float()\n",
    "                # labels = data['label']\n",
    "                features, labels = features.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                predictions = self.model(features)\n",
    "                loss = self.criterion(predictions, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                preds = torch.max(predictions.data, 1)[1]\n",
    "                train_acc += (preds==labels).sum().item()\n",
    "            \n",
    "            train_loss /= len(train)\n",
    "            train_acc /= len(train)\n",
    "\n",
    "            valid_loss = 0.0\n",
    "            valid_acc = 0.0\n",
    "            total = 0\n",
    "            self.model.eval()\n",
    "            for i, data in enumerate(test_loader):\n",
    "                features = data['feature']\n",
    "                labels = data['label']\n",
    "\n",
    "                features, labels = features.to(self.device), labels.to(self.device)\n",
    "                predictions = self.model(features)\n",
    "                loss = self.criterion(predictions,labels)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "                preds = torch.max(predictions.data, 1)[1]\n",
    "                valid_acc += (preds==labels).sum().item()\n",
    "                total += features.size(0)\n",
    "\n",
    "            valid_loss /= len(test)\n",
    "            valid_acc /= len(test)\n",
    "\n",
    "            print(\n",
    "                f'Epoch {epoch+1} Training Loss: {train_loss} Train_acc: {train_acc}'\n",
    "                f'|| Validation Loss: {valid_loss} Valid_acc: {valid_acc}'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmTrainVal(object):\n",
    "    def __init__(self, model,device, EPOCH, BATCH_SIZE, LR) -> None:\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.EPOCH = EPOCH\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.LR = LR\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.LR)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self, labels, features, transform, eval_intval=3):\n",
    "        dataset = SVRCDataset(features, labels, transform)\n",
    "        data_loader = DataLoader(\n",
    "            dataset, batch_sampler=BatchSampler(\n",
    "                SequentialSampler(dataset), \n",
    "                self.BATCH_SIZE, \n",
    "                drop_last=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.model.pretrain = False\n",
    "\n",
    "        for epoch in range(self.EPOCH):\n",
    "            if (epoch + 1) % eval_intval == 0:\n",
    "                self.model.eval()\n",
    "            else:\n",
    "                self.model.lstm.train()\n",
    "                self.model.full.train()\n",
    "\n",
    "            train_loss = 0.0\n",
    "            train_acc = 0.0\n",
    "\n",
    "            for i, data in enumerate(data_loader):\n",
    "                features  = data['feature'].float()\n",
    "                \n",
    "                labels = data['label']\n",
    "                features, labels = features.to(self.device), labels.to(self.device)\n",
    "                predictions = self.model(features)\n",
    "                loss = self.criterion(predictions, labels)\n",
    "\n",
    "                if not (epoch + 1) % eval_intval == 0:\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                preds = torch.max(predictions.data, 1)[1]\n",
    "                train_acc += (preds==labels).sum().item()\n",
    "\n",
    "            train_loss /= len(dataset)\n",
    "            train_acc /= len(dataset)\n",
    "\n",
    "            print('Epoch {} - {} Loss: {} Acc: {} LSTM'.format(\n",
    "                epoch+1, 'Train' if not (epoch + 1) % eval_intval == 0 else 'Valid', \n",
    "                train_loss, train_acc\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "WeightsPath = './models/weights_resnet18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet: \n",
      "150539\n",
      "Epoch 1 Training Loss: 0.024475088597899253 Train_acc: 0.7605404579544172|| Validation Loss: 0.01592618384509064 Valid_acc: 0.8422455748783285\n",
      "Epoch 2 Training Loss: 0.013247700232216423 Train_acc: 0.8697613243079866|| Validation Loss: 0.010955648369718301 Valid_acc: 0.8920766297777365\n",
      "Epoch 3 Training Loss: 0.009097111920864289 Train_acc: 0.9110928065152551|| Validation Loss: 0.010903670767681848 Valid_acc: 0.9068167023156328\n",
      "Epoch 4 Training Loss: 0.00716468797997593 Train_acc: 0.9294601398973024|| Validation Loss: 0.007357738582379434 Valid_acc: 0.9282215815741344\n",
      "Epoch 5 Training Loss: 0.005694102683291168 Train_acc: 0.9441473638060569|| Validation Loss: 0.007043369710279112 Valid_acc: 0.9330574413342013\n",
      "Time:2.2e+02min\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "X = image_paths\n",
    "y = labels\n",
    "\n",
    "# resnet18 Model\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "model = SVRC()\n",
    "if torch.cuda.is_available:\n",
    "    model.to(device)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.pretrain = True\n",
    "trainer = ResnetTrainVal(model, device, 5, 30, 1e-3)\n",
    "trainer.train(y, X, data_transform['train'])\n",
    "\n",
    "torch.save(model.state_dict(),WeightsPath+'_70')\n",
    "\n",
    "end_time = time.time()\n",
    "print('Time:{:.2}min'.format((end_time-start_time)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset for test\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for video in videos[50:70]:\n",
    "    base = os.path.join(image_base, video.split('.')[0])\n",
    "    # image_paths += list(map(\n",
    "    #     lambda img: os.path.join(base, img), \n",
    "    #     os.listdir(base)\n",
    "    # ))\n",
    "    image_paths += list(map(\n",
    "        lambda img: base + '/' + img,\n",
    "        os.listdir(base)\n",
    "    ))\n",
    "    labels += list(map(\n",
    "        lambda img: int(img.split('.')[0].split('-')[1]), \n",
    "        os.listdir(base)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for test of ResNet\n",
    "def sort_images(x):\n",
    "    vid = int(x[0].split('_')[-1].split('/')[0])\n",
    "    frame = int(x[0].split('/')[-1].split('-')[0])\n",
    "    return vid*7200 + frame\n",
    "\n",
    "image_paths_test = []\n",
    "labels_test = []\n",
    "for path,label in sorted(zip(image_paths, labels), key=sort_images):\n",
    "    image_paths_test.append(path)\n",
    "    labels_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc:0.9575570223076281\n"
     ]
    }
   ],
   "source": [
    "WeightsPath = './models/weights_resnet18_70'\n",
    "X = image_paths_test\n",
    "y = labels_test\n",
    "model = SVRC()\n",
    "model.pretrain = True\n",
    "model.load_state_dict(torch.load(WeightsPath))\n",
    "a = model.predict(X, y, 30, transform = data_transform['train'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.3513061202120706 Acc: 0.6672370580822758 LSTM\n",
      "Epoch 2 - Train Loss: 0.22994594864438234 Acc: 0.7781425389547887 LSTM\n",
      "Epoch 3 - Train Loss: 0.17711631583863016 Acc: 0.8305472502638835 LSTM\n",
      "Epoch 4 - Train Loss: 0.14286621200371366 Acc: 0.8634966543753516 LSTM\n",
      "Epoch 5 - Valid Loss: 1.6568060865719982 Acc: 0.06767043156000502 LSTM\n",
      "Epoch 6 - Train Loss: 0.13071372540655407 Acc: 0.8784601291750559 LSTM\n",
      "Epoch 7 - Train Loss: 0.02568127496087503 Acc: 0.9765132034762877 LSTM\n",
      "Epoch 8 - Train Loss: 0.01870487627525775 Acc: 0.9830696048024478 LSTM\n",
      "Epoch 9 - Train Loss: 0.014655133675175227 Acc: 0.9870452949683107 LSTM\n",
      "Epoch 10 - Valid Loss: 0.013645206177535833 Acc: 0.9879659811119843 LSTM\n",
      "Epoch 11 - Train Loss: 0.011677250751410293 Acc: 0.9900026504601106 LSTM\n",
      "Epoch 12 - Train Loss: 0.009359580709360157 Acc: 0.9922857660992203 LSTM\n",
      "Epoch 13 - Train Loss: 0.007874114600798314 Acc: 0.9938062932152871 LSTM\n",
      "Epoch 14 - Train Loss: 0.006684266908701929 Acc: 0.9946665302687194 LSTM\n",
      "Epoch 15 - Valid Loss: 0.00744534657739287 Acc: 0.9938527925154726 LSTM\n",
      "Epoch 16 - Train Loss: 0.006054125570975509 Acc: 0.9954477185118364 LSTM\n",
      "Epoch 17 - Train Loss: 0.005385688038841429 Acc: 0.996024309834137 LSTM\n",
      "Epoch 18 - Train Loss: 0.005054180858167087 Acc: 0.9962196068949162 LSTM\n",
      "Epoch 19 - Train Loss: 0.004537548167951986 Acc: 0.9967589987770684 LSTM\n",
      "Epoch 20 - Valid Loss: 0.005805930077007439 Acc: 0.995494217812022 LSTM\n",
      "Time:1.3e+03min\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "WeightsPath = './models/weights_resnet18_70'\n",
    "X = image_paths_lstm\n",
    "y = labels_lstm\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "# SVRC Model\n",
    "model = SVRC()\n",
    "if torch.cuda.is_available():\n",
    "    model.to(device)\n",
    "\n",
    "model.pretrain = False\n",
    "model.load_state_dict(torch.load(WeightsPath))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "trainer = LstmTrainVal(model, device, 20, 3, 1e-5)\n",
    "trainer.train(y, X, data_transform['train'])\n",
    "torch.save(model.state_dict(),WeightsPath+'_LSTM')\n",
    "end_time = time.time()\n",
    "print('Time:{:.2}min'.format((end_time-start_time)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc:0.9969922299273122\n"
     ]
    }
   ],
   "source": [
    "WeightsPath = './models/weights_resnet18_70_LSTM'\n",
    "X = image_paths_test\n",
    "y = labels_test\n",
    "model = SVRC()\n",
    "model.pretrain = False\n",
    "model.load_state_dict(torch.load(WeightsPath))\n",
    "a = model.predict(X, y, 3, transform = data_transform['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetEvaluator:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def predict(self, images, transform):\n",
    "        dataset = SVRCDataset(images, None, transform)\n",
    "        loader = DataLoader(dataset)\n",
    "        preds = []\n",
    "        self.model.eval()\n",
    "        for i,data in enumerate(loader):\n",
    "            feature = data['feature'].float().to(self.device)\n",
    "            pred = torch.max(self.model(feature).data, 1)[1]\n",
    "            preds.append(pred)\n",
    "        return preds\n",
    "\n",
    "    def eval(self, preds, labels):\n",
    "        acc = sum([p.item() == l for p,l in zip(preds, labels)]) / len(labels)\n",
    "        print('Accuracy: {}'.format(acc))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9578494443980282\n",
      "Time:1.8e+01min\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "WeightsPath = './models/weights_resnet18_70'\n",
    "X = image_paths_test\n",
    "y = labels_test\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# SVRC Model\n",
    "model = SVRC()\n",
    "if torch.cuda.is_available():\n",
    "    model.to(device)\n",
    "#print(model)\n",
    "\n",
    "model.pretrain = True\n",
    "model.load_state_dict(torch.load(WeightsPath), strict=False)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "evaluator = ResnetEvaluator(model, device)\n",
    "preds = evaluator.predict(X, data_transform['train'])\n",
    "acc = evaluator.eval(preds, y)\n",
    "\n",
    "end_time = time.time()\n",
    "print('Time:{:.2}min'.format((end_time-start_time)/60.0))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7bb744823c5315bc838d6f85bb474c2716845bb0b4d758ac389cca5a4bd648da"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
